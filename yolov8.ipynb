{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade git+https://github.com/keras-team/keras-cv -q --break-system-packages\n",
    "# %pip install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2 --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATIO = 0.2\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 5\n",
    "GLOBAL_CLIPNORM = 10.0\n",
    "IMAGE_WIDTH = 3000\n",
    "IMAGE_HEIGHT = 4000\n",
    "\n",
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "TF_DISABLE_MKL=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = [\n",
    "    \"neutrofilo\",\n",
    "    \"linfocito\",\n",
    "    \"monocito\",\n",
    "    \"bastonete\",\n",
    "    \"metamielocito\",\n",
    "    \"eosinofilo\",\n",
    "]\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "\n",
    "# Path to images and annotations\n",
    "path_images = \"/home/gabriela/projetos/yolov8keras/Bach1\"\n",
    "path_annot = \"/home/gabriela/projetos/yolov8keras/Bach1/annotations\"\n",
    "\n",
    "path_test_img = \"/home/gabriela/projetos/yolov8keras/test\"\n",
    "path_test_annot = \"/home/gabriela/projetos/yolov8keras/test/annotations\"\n",
    "\n",
    "# Get all XML file paths in path_annot and sort them\n",
    "xml_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_annot, file_name)\n",
    "        for file_name in os.listdir(path_annot)\n",
    "        if file_name.endswith(\".xml\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "xml_test_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_test_annot, file_name)\n",
    "        for file_name in os.listdir(path_test_annot)\n",
    "        if file_name.endswith(\".xml\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get all JPEG image file paths in path_images and sort them\n",
    "jpg_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_images, file_name)\n",
    "        for file_name in os.listdir(path_images)\n",
    "        if file_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "jpg_test_files = sorted(\n",
    "    [\n",
    "        os.path.join(path_test_img, file_name)\n",
    "        for file_name in os.listdir(path_test_img)\n",
    "        if file_name.endswith(\".jpg\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutrofilo'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the objects in the annotation xml file\n",
    "def parse_annotation(xml_file, path_img):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    image_name = root.find(\"filename\").text\n",
    "    image_path = os.path.join(path_img, image_name)\n",
    "\n",
    "    boxes = []\n",
    "    classes = []\n",
    "    for obj in root.find(\"objects\"):\n",
    "        cls = obj.tag\n",
    "        # print(cls)\n",
    "        classes.append(cls)\n",
    "\n",
    "        if(obj.find(\"bbox\") != None):\n",
    "            bbox = obj.find(\"bbox\")\n",
    "            min_x, min_y, width, height = normalize_bounding_box(float(bbox.find(\"x\").text), float(bbox.find(\"y\").text), float(bbox.find(\"width\").text), float(bbox.find(\"height\").text))\n",
    "            boxes.append([min_x, min_y, width, height])\n",
    "        else:\n",
    "            xCoords = []\n",
    "            yCoords = []\n",
    "            for coord in obj:\n",
    "                if (coord.tag.find(\"x\") != -1):\n",
    "                    xCoords.append(float(coord.text))\n",
    "                elif (coord.tag.find(\"y\") != -1):\n",
    "                    yCoords.append(float(coord.text))\n",
    "\n",
    "            xmin, ymin, width, height = calculate_bounding_box_normalized(xCoords, yCoords)\n",
    "            boxes.append([xmin, ymin, width, height])\n",
    "\n",
    "    class_ids = [\n",
    "        list(class_mapping.keys())[list(class_mapping.values()).index(cls)]\n",
    "        for cls in classes\n",
    "    ]\n",
    "    return image_path, boxes, class_ids\n",
    "\n",
    "#calculate bounding boxes with points provided\n",
    "def calculate_bounding_box_normalized(xCoords, yCoords):\n",
    "    points = np.array([xCoords, yCoords])\n",
    "\n",
    "    min_x = float(np.min(points[0, :]))\n",
    "    min_x = (min_x/IMAGE_WIDTH)*640\n",
    "    min_y = float(np.min(points[1, :]))\n",
    "    # min_y = ((IMAGE_HEIGHT - min_y)/IMAGE_HEIGHT)*640\n",
    "    min_y = (min_y/IMAGE_HEIGHT)*640\n",
    "\n",
    "    max_x = float(np.max(points[0, :]))\n",
    "    max_x = (max_x/IMAGE_WIDTH)*640\n",
    "    max_y = float(np.max(points[1, :]))\n",
    "    # max_y = ((IMAGE_HEIGHT - max_y)/IMAGE_HEIGHT)*640\n",
    "    max_y = (max_y/IMAGE_HEIGHT)*640\n",
    "\n",
    "    width =  max_x - min_x\n",
    "    height = max_y - min_y\n",
    "\n",
    "    return (min_x, min_y, width, height)\n",
    "\n",
    "def normalize_bounding_box(xmin, ymin, width, height):\n",
    "\n",
    "    min_x = (xmin/IMAGE_WIDTH)*640\n",
    "    # min_y = ((IMAGE_HEIGHT - ymin)/IMAGE_HEIGHT)*640\n",
    "    min_y = (ymin/IMAGE_HEIGHT)*640\n",
    "    width = (width/IMAGE_WIDTH)*640\n",
    "    height = (height/IMAGE_HEIGHT)*640\n",
    "\n",
    "    return (min_x, min_y, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:00<00:00, 3908.46it/s]\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "bbox = []\n",
    "classes = []\n",
    "\n",
    "for xml_file in tqdm(xml_files):\n",
    "    image_path, boxes, class_ids = parse_annotation(xml_file, path_images)\n",
    "    image_paths.append(image_path)\n",
    "    bbox.append(boxes)\n",
    "    classes.append(class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 4510.15it/s]\n"
     ]
    }
   ],
   "source": [
    "image_test_paths = []\n",
    "bbox_test = []\n",
    "classes_test = []\n",
    "\n",
    "for xml_file in tqdm(xml_test_files):\n",
    "    image_path, boxes, class_ids = parse_annotation(xml_file, path_test_img)\n",
    "    image_test_paths.append(image_path)\n",
    "    bbox_test.append(boxes)\n",
    "    classes_test.append(class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (640, 640), interpolation=cv2.INTER_CUBIC)\n",
    "    return image\n",
    "\n",
    "def load_all_images(paths):\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        image = load_image(path)\n",
    "        images.append(image)\n",
    "        # print(image.shape)\n",
    "    return images\n",
    "\n",
    "\n",
    "images = load_all_images(image_paths)\n",
    "\n",
    "test_images = load_all_images(image_test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 640, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[211.64500395373847, 260.3884766351209, 27.2868875067318, 20.976794770800076]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox[100][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBoundingBoxes(imageData, imageOutputPath, bboxes, labels, color):\n",
    "    \"\"\"Draw bounding boxes on an image.\n",
    "    imageData: image data in numpy array format\n",
    "    imageOutputPath: output image file path\n",
    "    inferenceResults: inference results array off object (l,t,w,h)\n",
    "    colorMap: Bounding box color candidates, list of RGB tuples.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for box in bboxes:\n",
    "        left = int(box[0])\n",
    "        bottom = int(box[1])\n",
    "        right = int(box[0]) + int(box[2])\n",
    "        top = int(box[1]) + int(box[3])\n",
    "        label = class_mapping[int(labels[i])]\n",
    "        i+=1\n",
    "        imgHeight, imgWidth, _ = imageData.shape\n",
    "        thick = int((imgHeight + imgWidth) // 900)\n",
    "        print (left, bottom, imgHeight, imgWidth)\n",
    "        print (label)\n",
    "        cv2.rectangle(imageData,(left, top), (right, bottom), color, thick)\n",
    "        cv2.putText(imageData, label, (left, top - 20), 0, 1e-3 * imgHeight, color, thick//3)\n",
    "    cv2.imwrite(imageOutputPath, imageData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 260 640 640\n",
      "bastonete\n"
     ]
    }
   ],
   "source": [
    "# print(len(images))\n",
    "index = 100\n",
    "drawBoundingBoxes(images[index], '/home/gabriela/projetos/yolov8keras/output/example_Bach1.jpg', bbox[index], classes[index], (0, 0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
    "# print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragged_bboxes = tf.ragged.constant(bbox, dtype=tf.float32)\n",
    "ragged_classes = tf.ragged.constant(classes, dtype=tf.int64)\n",
    "\n",
    "labels = {\n",
    "    \"boxes\": ragged_bboxes.to_tensor(),\n",
    "    \"classes\": ragged_classes.to_tensor(),\n",
    "}\n",
    "\n",
    "# print(labels[\"boxes\"].type())\n",
    "print(len(labels[\"classes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras_cv.models.YOLOV8Detector(\n",
    "#     num_classes=len(class_mapping),\n",
    "#     bounding_box_format=\"xywh\",\n",
    "#     backbone=keras_cv.models.YOLOV8Backbone.from_preset(\n",
    "#         \"yolo_v8_s_backbone_coco\"\n",
    "#     ),\n",
    "#     fpn_depth=2\n",
    "# )\n",
    "\n",
    "backbone=keras_cv.models.YOLOV8Backbone.from_preset(\"yolo_v8_xs_backbone_coco\")\n",
    "\n",
    "model = keras_cv.models.YOLOV8Detector(\n",
    "    num_classes=len(class_mapping),\n",
    "    bounding_box_format=\"xywh\",\n",
    "    backbone=backbone,\n",
    "    fpn_depth=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    global_clipnorm=GLOBAL_CLIPNORM,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer, classification_loss=\"binary_crossentropy\", box_loss=\"ciou\"\n",
    ")\n",
    "\n",
    "# model.compile(\n",
    "#     classification_loss='binary_crossentropy',\n",
    "#     box_loss='ciou',\n",
    "#     optimizer=tf.optimizers.SGD(global_clipnorm=10.0),\n",
    "#     jit_compile=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(images, labels, batch_size=4, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_images)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
